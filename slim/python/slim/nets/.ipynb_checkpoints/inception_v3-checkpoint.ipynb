{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load inception_v3.py\n",
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Contains the definition for inception v3 classification network.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(0.0, stddev)\n",
    "\n",
    "\n",
    "def inception_v3_base(inputs,\n",
    "                      final_endpoint='Mixed_7c',\n",
    "                      min_depth=16,\n",
    "                      depth_multiplier=1.0,\n",
    "                      scope=None):\n",
    "  \"\"\"Inception model from http://arxiv.org/abs/1512.00567.\n",
    "\n",
    "  Constructs an Inception v3 network from inputs to the given final endpoint.\n",
    "  This method can construct the network up to the final inception block\n",
    "  Mixed_7c.\n",
    "\n",
    "  Note that the names of the layers in the paper do not correspond to the names\n",
    "  of the endpoints registered by this function although they build the same\n",
    "  network.\n",
    "\n",
    "  Here is a mapping from the old_names to the new names:\n",
    "  Old name          | New name\n",
    "  =======================================\n",
    "  conv0             | Conv2d_1a_3x3\n",
    "  conv1             | Conv2d_2a_3x3\n",
    "  conv2             | Conv2d_2b_3x3\n",
    "  pool1             | MaxPool_3a_3x3\n",
    "  conv3             | Conv2d_3b_1x1\n",
    "  conv4             | Conv2d_4a_3x3\n",
    "  pool2             | MaxPool_5a_3x3\n",
    "  mixed_35x35x256a  | Mixed_5b\n",
    "  mixed_35x35x288a  | Mixed_5c\n",
    "  mixed_35x35x288b  | Mixed_5d\n",
    "  mixed_17x17x768a  | Mixed_6a\n",
    "  mixed_17x17x768b  | Mixed_6b\n",
    "  mixed_17x17x768c  | Mixed_6c\n",
    "  mixed_17x17x768d  | Mixed_6d\n",
    "  mixed_17x17x768e  | Mixed_6e\n",
    "  mixed_8x8x1280a   | Mixed_7a\n",
    "  mixed_8x8x2048a   | Mixed_7b\n",
    "  mixed_8x8x2048b   | Mixed_7c\n",
    "\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to. It\n",
    "      can be one of ['Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n",
    "      'MaxPool_3a_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', 'MaxPool_5a_3x3',\n",
    "      'Mixed_5b', 'Mixed_5c', 'Mixed_5d', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c',\n",
    "      'Mixed_6d', 'Mixed_6e', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c'].\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    scope: Optional variable_scope.\n",
    "\n",
    "  Returns:\n",
    "    tensor_out: output tensor corresponding to the final_endpoint.\n",
    "    end_points: a set of activations for external use, for example summaries or\n",
    "                losses.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "                or depth_multiplier <= 0\n",
    "  \"\"\"\n",
    "  # end_points will collect relevant activations for external use, for example\n",
    "  # summaries or losses.\n",
    "  end_points = {}\n",
    "\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n",
    "\n",
    "  with tf.variable_scope(scope, 'InceptionV3', [inputs]):\n",
    "    with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                        stride=1, padding='VALID'):\n",
    "      # 299 x 299 x 3\n",
    "      end_point = 'Conv2d_1a_3x3'\n",
    "      net = slim.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 149 x 149 x 32\n",
    "      end_point = 'Conv2d_2a_3x3'\n",
    "      net = slim.conv2d(net, depth(32), [3, 3], scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 147 x 147 x 32\n",
    "      end_point = 'Conv2d_2b_3x3'\n",
    "      net = slim.conv2d(net, depth(64), [3, 3], padding='SAME', scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 147 x 147 x 64\n",
    "      end_point = 'MaxPool_3a_3x3'\n",
    "      net = slim.max_pool2d(net, [3, 3], stride=2, scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 73 x 73 x 64\n",
    "      end_point = 'Conv2d_3b_1x1'\n",
    "      net = slim.conv2d(net, depth(80), [1, 1], scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 73 x 73 x 80.\n",
    "      end_point = 'Conv2d_4a_3x3'\n",
    "      net = slim.conv2d(net, depth(192), [3, 3], scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 71 x 71 x 192.\n",
    "      end_point = 'MaxPool_5a_3x3'\n",
    "      net = slim.max_pool2d(net, [3, 3], stride=2, scope=end_point)\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # 35 x 35 x 192.\n",
    "\n",
    "    # Inception blocks\n",
    "    with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                        stride=1, padding='SAME'):\n",
    "      # mixed: 35 x 35 x 256.\n",
    "      end_point = 'Mixed_5b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(48), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(64), [5, 5],\n",
    "                                 scope='Conv2d_0b_5x5')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(32), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_1: 35 x 35 x 288.\n",
    "      end_point = 'Mixed_5c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(48), [1, 1], scope='Conv2d_0b_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(64), [5, 5],\n",
    "                                 scope='Conv_1_0c_5x5')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(64), [1, 1],\n",
    "                                 scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(64), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_2: 35 x 35 x 288.\n",
    "      end_point = 'Mixed_5d'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(48), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(64), [5, 5],\n",
    "                                 scope='Conv2d_0b_5x5')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0c_3x3')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(64), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_3: 17 x 17 x 768.\n",
    "      end_point = 'Mixed_6a'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(384), [3, 3], stride=2,\n",
    "                                 padding='VALID', scope='Conv2d_1a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(64), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(96), [3, 3],\n",
    "                                 scope='Conv2d_0b_3x3')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(96), [3, 3], stride=2,\n",
    "                                 padding='VALID', scope='Conv2d_1a_1x1')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.max_pool2d(net, [3, 3], stride=2, padding='VALID',\n",
    "                                     scope='MaxPool_1a_3x3')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed4: 17 x 17 x 768.\n",
    "      end_point = 'Mixed_6b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(128), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(128), [1, 7],\n",
    "                                 scope='Conv2d_0b_1x7')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0c_7x1')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(128), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [7, 1],\n",
    "                                 scope='Conv2d_0b_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [1, 7],\n",
    "                                 scope='Conv2d_0c_1x7')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(128), [7, 1],\n",
    "                                 scope='Conv2d_0d_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0e_1x7')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(192), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_5: 17 x 17 x 768.\n",
    "      end_point = 'Mixed_6c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(160), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(160), [1, 7],\n",
    "                                 scope='Conv2d_0b_1x7')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0c_7x1')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(160), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [7, 1],\n",
    "                                 scope='Conv2d_0b_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [1, 7],\n",
    "                                 scope='Conv2d_0c_1x7')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [7, 1],\n",
    "                                 scope='Conv2d_0d_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0e_1x7')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(192), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # mixed_6: 17 x 17 x 768.\n",
    "      end_point = 'Mixed_6d'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(160), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(160), [1, 7],\n",
    "                                 scope='Conv2d_0b_1x7')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0c_7x1')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(160), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [7, 1],\n",
    "                                 scope='Conv2d_0b_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [1, 7],\n",
    "                                 scope='Conv2d_0c_1x7')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(160), [7, 1],\n",
    "                                 scope='Conv2d_0d_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0e_1x7')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(192), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_7: 17 x 17 x 768.\n",
    "      end_point = 'Mixed_6e'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0b_1x7')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0c_7x1')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0b_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0c_1x7')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0d_7x1')\n",
    "          branch_2 = slim.conv2d(branch_2, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0e_1x7')\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(branch_3, depth(192), [1, 1],\n",
    "                                 scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_8: 8 x 8 x 1280.\n",
    "      end_point = 'Mixed_7a'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_0 = slim.conv2d(branch_0, depth(320), [3, 3], stride=2,\n",
    "                                 padding='VALID', scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(192), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [1, 7],\n",
    "                                 scope='Conv2d_0b_1x7')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [7, 1],\n",
    "                                 scope='Conv2d_0c_7x1')\n",
    "          branch_1 = slim.conv2d(branch_1, depth(192), [3, 3], stride=2,\n",
    "                                 padding='VALID', scope='Conv2d_1a_3x3')\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.max_pool2d(net, [3, 3], stride=2, padding='VALID',\n",
    "                                     scope='MaxPool_1a_3x3')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "      # mixed_9: 8 x 8 x 2048.\n",
    "      end_point = 'Mixed_7b'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(320), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(384), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = tf.concat(3, [\n",
    "              slim.conv2d(branch_1, depth(384), [1, 3], scope='Conv2d_0b_1x3'),\n",
    "              slim.conv2d(branch_1, depth(384), [3, 1], scope='Conv2d_0b_3x1')])\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(448), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(\n",
    "              branch_2, depth(384), [3, 3], scope='Conv2d_0b_3x3')\n",
    "          branch_2 = tf.concat(3, [\n",
    "              slim.conv2d(branch_2, depth(384), [1, 3], scope='Conv2d_0c_1x3'),\n",
    "              slim.conv2d(branch_2, depth(384), [3, 1], scope='Conv2d_0d_3x1')])\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(192), [1, 1], scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "\n",
    "      # mixed_10: 8 x 8 x 2048.\n",
    "      end_point = 'Mixed_7c'\n",
    "      with tf.variable_scope(end_point):\n",
    "        with tf.variable_scope('Branch_0'):\n",
    "          branch_0 = slim.conv2d(net, depth(320), [1, 1], scope='Conv2d_0a_1x1')\n",
    "        with tf.variable_scope('Branch_1'):\n",
    "          branch_1 = slim.conv2d(net, depth(384), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_1 = tf.concat(3, [\n",
    "              slim.conv2d(branch_1, depth(384), [1, 3], scope='Conv2d_0b_1x3'),\n",
    "              slim.conv2d(branch_1, depth(384), [3, 1], scope='Conv2d_0c_3x1')])\n",
    "        with tf.variable_scope('Branch_2'):\n",
    "          branch_2 = slim.conv2d(net, depth(448), [1, 1], scope='Conv2d_0a_1x1')\n",
    "          branch_2 = slim.conv2d(\n",
    "              branch_2, depth(384), [3, 3], scope='Conv2d_0b_3x3')\n",
    "          branch_2 = tf.concat(3, [\n",
    "              slim.conv2d(branch_2, depth(384), [1, 3], scope='Conv2d_0c_1x3'),\n",
    "              slim.conv2d(branch_2, depth(384), [3, 1], scope='Conv2d_0d_3x1')])\n",
    "        with tf.variable_scope('Branch_3'):\n",
    "          branch_3 = slim.avg_pool2d(net, [3, 3], scope='AvgPool_0a_3x3')\n",
    "          branch_3 = slim.conv2d(\n",
    "              branch_3, depth(192), [1, 1], scope='Conv2d_0b_1x1')\n",
    "        net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])\n",
    "      end_points[end_point] = net\n",
    "      if end_point == final_endpoint: return net, end_points\n",
    "    raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
    "\n",
    "\n",
    "def inception_v3(inputs,\n",
    "                 num_classes=1000,\n",
    "                 is_training=True,\n",
    "                 dropout_keep_prob=0.8,\n",
    "                 min_depth=16,\n",
    "                 depth_multiplier=1.0,\n",
    "                 prediction_fn=slim.softmax,\n",
    "                 spatial_squeeze=True,\n",
    "                 reuse=None,\n",
    "                 scope='InceptionV3'):\n",
    "  \"\"\"Inception model from http://arxiv.org/abs/1512.00567.\n",
    "\n",
    "  \"Rethinking the Inception Architecture for Computer Vision\"\n",
    "\n",
    "  Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,\n",
    "  Zbigniew Wojna.\n",
    "\n",
    "  With the default arguments this method constructs the exact model defined in\n",
    "  the paper. However, one can experiment with variations of the inception_v3\n",
    "  network by changing arguments dropout_keep_prob, min_depth and\n",
    "  depth_multiplier.\n",
    "\n",
    "  The default image size used to train this network is 299x299.\n",
    "\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    num_classes: number of predicted classes.\n",
    "    is_training: whether is training or not.\n",
    "    dropout_keep_prob: the percentage of activation values that are retained.\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    prediction_fn: a function to get predictions out of logits.\n",
    "    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n",
    "        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n",
    "    reuse: whether or not the network and its variables should be reused. To be\n",
    "      able to reuse 'scope' must be given.\n",
    "    scope: Optional variable_scope.\n",
    "\n",
    "  Returns:\n",
    "    logits: the pre-softmax activations, a tensor of size\n",
    "      [batch_size, num_classes]\n",
    "    end_points: a dictionary from components of the network to the corresponding\n",
    "      activation.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: if 'depth_multiplier' is less than or equal to zero.\n",
    "  \"\"\"\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n",
    "\n",
    "  with tf.variable_scope(scope, 'InceptionV3', [inputs, num_classes],\n",
    "                         reuse=reuse) as scope:\n",
    "    with slim.arg_scope([slim.batch_norm, slim.dropout],\n",
    "                        is_training=is_training):\n",
    "      net, end_points = inception_v3_base(\n",
    "          inputs, scope=scope, min_depth=min_depth,\n",
    "          depth_multiplier=depth_multiplier)\n",
    "\n",
    "      # Auxiliary Head logits\n",
    "      with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                          stride=1, padding='SAME'):\n",
    "        aux_logits = end_points['Mixed_6e']\n",
    "        with tf.variable_scope('AuxLogits'):\n",
    "          aux_logits = slim.avg_pool2d(\n",
    "              aux_logits, [5, 5], stride=3, padding='VALID',\n",
    "              scope='AvgPool_1a_5x5')\n",
    "          aux_logits = slim.conv2d(aux_logits, depth(128), [1, 1],\n",
    "                                   scope='Conv2d_1b_1x1')\n",
    "\n",
    "          # Shape of feature map before the final layer.\n",
    "          kernel_size = _reduced_kernel_size_for_small_input(\n",
    "              aux_logits, [5, 5])\n",
    "          aux_logits = slim.conv2d(\n",
    "              aux_logits, depth(768), kernel_size,\n",
    "              weights_initializer=trunc_normal(0.01),\n",
    "              padding='VALID', scope='Conv2d_2a_{}x{}'.format(*kernel_size))\n",
    "          aux_logits = slim.conv2d(\n",
    "              aux_logits, num_classes, [1, 1], activation_fn=None,\n",
    "              normalizer_fn=None, weights_initializer=trunc_normal(0.001),\n",
    "              scope='Conv2d_2b_1x1')\n",
    "          if spatial_squeeze:\n",
    "            aux_logits = tf.squeeze(aux_logits, [1, 2], name='SpatialSqueeze')\n",
    "          end_points['AuxLogits'] = aux_logits\n",
    "\n",
    "      # Final pooling and prediction\n",
    "      with tf.variable_scope('Logits'):\n",
    "        kernel_size = _reduced_kernel_size_for_small_input(net, [8, 8])\n",
    "        net = slim.avg_pool2d(net, kernel_size, padding='VALID',\n",
    "                              scope='AvgPool_1a_{}x{}'.format(*kernel_size))\n",
    "        # 1 x 1 x 2048\n",
    "        net = slim.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
    "        end_points['PreLogits'] = net\n",
    "        # 2048\n",
    "        logits = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\n",
    "                             normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        if spatial_squeeze:\n",
    "          logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n",
    "        # 1000\n",
    "      end_points['Logits'] = logits\n",
    "      end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n",
    "  return logits, end_points\n",
    "inception_v3.default_image_size = 299\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _reduced_kernel_size_for_small_input(input_tensor, kernel_size):\n",
    "  \"\"\"Define kernel size which is automatically reduced for small input.\n",
    "\n",
    "  If the shape of the input images is unknown at graph construction time this\n",
    "  function assumes that the input images are is large enough.\n",
    "\n",
    "  Args:\n",
    "    input_tensor: input tensor of size [batch_size, height, width, channels].\n",
    "    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n",
    "\n",
    "  Returns:\n",
    "    a tensor with the kernel size.\n",
    "\n",
    "  TODO(jrru): Make this function work with unknown shapes. Theoretically, this\n",
    "  can be done with the code below. Problems are two-fold: (1) If the shape was\n",
    "  known, it will be lost. (2) inception.slim.ops._two_element_tuple cannot\n",
    "  handle tensors that define the kernel size.\n",
    "      shape = tf.shape(input_tensor)\n",
    "      return = tf.pack([tf.minimum(shape[1], kernel_size[0]),\n",
    "                        tf.minimum(shape[2], kernel_size[1])])\n",
    "\n",
    "  \"\"\"\n",
    "  shape = input_tensor.get_shape().as_list()\n",
    "  if shape[1] is None or shape[2] is None:\n",
    "    kernel_size_out = kernel_size\n",
    "  else:\n",
    "    kernel_size_out = [min(shape[1], kernel_size[0]),\n",
    "                       min(shape[2], kernel_size[1])]\n",
    "  return kernel_size_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_v3_arg_scope(weight_decay=0.00004,\n",
    "                           stddev=0.1,\n",
    "                           batch_norm_var_collection='moving_vars'):\n",
    "  \"\"\"Defines the default InceptionV3 arg scope.\n",
    "\n",
    "  Args:\n",
    "    weight_decay: The weight decay to use for regularizing the model.\n",
    "    stddev: The standard deviation of the trunctated normal weight initializer.\n",
    "    batch_norm_var_collection: The name of the collection for the batch norm\n",
    "      variables.\n",
    "\n",
    "  Returns:\n",
    "    An `arg_scope` to use for the inception v3 model.\n",
    "  \"\"\"\n",
    "  batch_norm_params = {\n",
    "      # Decay for the moving averages.\n",
    "      'decay': 0.9997,\n",
    "      # epsilon to prevent 0s in variance.\n",
    "      'epsilon': 0.001,\n",
    "      # collection containing update_ops.\n",
    "      'updates_collections': tf.GraphKeys.UPDATE_OPS,\n",
    "      # collection containing the moving mean and moving variance.\n",
    "      'variables_collections': {\n",
    "          'beta': None,\n",
    "          'gamma': None,\n",
    "          'moving_mean': [batch_norm_var_collection],\n",
    "          'moving_variance': [batch_norm_var_collection],\n",
    "      }\n",
    "  }\n",
    "\n",
    "  # Set weight_decay for weights in Conv and FC layers.\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d],\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "        activation_fn=tf.nn.relu,\n",
    "        normalizer_fn=slim.batch_norm,\n",
    "        normalizer_params=batch_norm_params) as sc:\n",
    "      return sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  tf.test.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
